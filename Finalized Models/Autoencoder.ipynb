{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18737/18737 [==============================] - 24s 1ms/step - loss: 0.0628\n",
      "Epoch 2/10\n",
      "18737/18737 [==============================] - 24s 1ms/step - loss: 0.0605\n",
      "Epoch 3/10\n",
      "18737/18737 [==============================] - 22s 1ms/step - loss: 0.0602\n",
      "Epoch 4/10\n",
      "18737/18737 [==============================] - 24s 1ms/step - loss: 0.0600\n",
      "Epoch 5/10\n",
      "18737/18737 [==============================] - 27s 1ms/step - loss: 0.0599\n",
      "Epoch 6/10\n",
      "18737/18737 [==============================] - 20s 1ms/step - loss: 0.0598\n",
      "Epoch 7/10\n",
      "18737/18737 [==============================] - 29s 2ms/step - loss: 0.0598\n",
      "Epoch 8/10\n",
      "18737/18737 [==============================] - 24s 1ms/step - loss: 0.0597\n",
      "Epoch 9/10\n",
      "18737/18737 [==============================] - 25s 1ms/step - loss: 0.0597\n",
      "Epoch 10/10\n",
      "12291/18737 [==================>...........] - ETA: 4s - loss: 0.0597"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = pd.read_csv('../Data Preprocessing/Final_Out.csv')\n",
    "\n",
    "X_train = X[X['Day'] < 29]\n",
    "X_test = X[X['Day'] >= 29]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.to_numpy())\n",
    "X_test_scaled = scaler.transform(X_test.to_numpy())\n",
    "\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "X_train_copy = X_train.drop(columns=['Next Time to Fine Arts Annex', 'Next Time to Loyola House of Studies', 'Next Time to Grade School', 'Next Time to Gate 2.5', 'Next Time to Leong Hall', 'Next Time to Xavier Hall'])\n",
    "X_test_copy = X_test.drop(columns=['Next Time to Fine Arts Annex', 'Next Time to Loyola House of Studies', 'Next Time to Grade School', 'Next Time to Gate 2.5', 'Next Time to Leong Hall', 'Next Time to Xavier Hall'])\n",
    "\n",
    "Y_train_copy = X_train[['Next Time to Fine Arts Annex', 'Next Time to Loyola House of Studies', 'Next Time to Grade School', 'Next Time to Gate 2.5', 'Next Time to Leong Hall', 'Next Time to Xavier Hall']]\n",
    "Y_test_copy = X_test[['Next Time to Fine Arts Annex', 'Next Time to Loyola House of Studies', 'Next Time to Grade School', 'Next Time to Gate 2.5', 'Next Time to Leong Hall', 'Next Time to Xavier Hall']]\n",
    "\n",
    "autoe_data = []\n",
    "r2_data = []\n",
    "\n",
    "for i in range(1, len(X_train_copy.columns) + 1):\n",
    "    # Define the autoencoder architecture\n",
    "    input_dim = X_train_scaled.shape[1]\n",
    "    encoding_dim_small = i  # Choose a suitable encoding dimension\n",
    "\n",
    "    input_layer_small = Input(shape=(input_dim,))\n",
    "    encoded_small = Dense(encoding_dim_small, activation=\"relu\")(input_layer_small)\n",
    "    decoded_small = Dense(input_dim, activation=\"sigmoid\")(encoded_small)\n",
    "\n",
    "    autoencoder_small = Model(input_layer_small, decoded_small)\n",
    "    autoencoder_small.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "    # Train the autoencoder\n",
    "    autoencoder_small.fit(X_train_scaled, X_train_scaled, epochs=10, batch_size=32)\n",
    "\n",
    "    layer_names = [layer.name for layer in autoencoder_small.layers]\n",
    "\n",
    "    # Use encoded features for further analysis\n",
    "    bottleneck_layer_small = autoencoder_small.get_layer(layer_names[1])\n",
    "    X_train_bottleneck = bottleneck_layer_small(X_train_scaled)\n",
    "\n",
    "    np.savetxt(f'Autoencoder Files/ae-train-{i}.txt', X_train_bottleneck, fmt='%d')\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_bottleneck, Y_train_copy)\n",
    "\n",
    "    X_test_bottleneck = bottleneck_layer_small(X_test_scaled)\n",
    "    np.savetxt(f'Autoencoder Files/ae-test-{i}.txt', X_test_bottleneck, fmt='%d')\n",
    "    y_pred = model.predict(X_test_bottleneck)\n",
    "\n",
    "    r2 = r2_score(Y_test_copy, y_pred)\n",
    "    r2_data.append({\n",
    "        'Component Count': i,\n",
    "        'R^2': r2 \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive Numpy Data\n",
    "def fetch_ae_file(component_num: int, is_train: bool = True) -> np.array:\n",
    "    return np.loadtxt(f'Autoencoder Files/ae-{'train' if is_train else 'test'}-{component_num}.txt', dtype=float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
