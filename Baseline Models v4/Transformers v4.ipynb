{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyahabana/Library/Python/3.8/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/anyahabana/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from functools import lru_cache\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>start</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Time</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour_of_Day</th>\n",
       "      <th>IsEJeep1</th>\n",
       "      <th>IsEJeep2</th>\n",
       "      <th>...</th>\n",
       "      <th>Next Time to Xavier Hall</th>\n",
       "      <th>Next Time to Fine Arts Annex</th>\n",
       "      <th>Next Time to Loyola House of Studies</th>\n",
       "      <th>Next Time to Grade School</th>\n",
       "      <th>Next Time to Gate 2.5</th>\n",
       "      <th>Next Time to Leong Hall</th>\n",
       "      <th>Encoded Day</th>\n",
       "      <th>Encoded Station</th>\n",
       "      <th>Encoded Prev Station</th>\n",
       "      <th>Encoded Next Station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-23 17:12:39</td>\n",
       "      <td>79.0</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>29.299999</td>\n",
       "      <td>17:12:39</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>06:12:33</td>\n",
       "      <td>06:41:23</td>\n",
       "      <td>17:24:22</td>\n",
       "      <td>17:30:29</td>\n",
       "      <td>17:16:30</td>\n",
       "      <td>17:21:38</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-23 17:12:40</td>\n",
       "      <td>78.7</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>29.299999</td>\n",
       "      <td>17:12:40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>06:12:33</td>\n",
       "      <td>06:41:23</td>\n",
       "      <td>17:24:22</td>\n",
       "      <td>17:30:29</td>\n",
       "      <td>17:34:36</td>\n",
       "      <td>17:21:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-23 17:12:41</td>\n",
       "      <td>78.4</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>29.299999</td>\n",
       "      <td>17:12:41</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>06:12:33</td>\n",
       "      <td>06:41:23</td>\n",
       "      <td>17:24:22</td>\n",
       "      <td>17:30:29</td>\n",
       "      <td>17:34:36</td>\n",
       "      <td>17:21:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-10-23 17:12:42</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>29.299999</td>\n",
       "      <td>17:12:42</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>06:12:33</td>\n",
       "      <td>06:41:23</td>\n",
       "      <td>17:24:22</td>\n",
       "      <td>17:30:29</td>\n",
       "      <td>17:34:36</td>\n",
       "      <td>17:21:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-10-23 17:12:43</td>\n",
       "      <td>77.7</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>29.299999</td>\n",
       "      <td>17:12:43</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>06:12:33</td>\n",
       "      <td>06:41:23</td>\n",
       "      <td>17:24:22</td>\n",
       "      <td>17:30:29</td>\n",
       "      <td>17:34:36</td>\n",
       "      <td>17:21:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482694</th>\n",
       "      <td>482695</td>\n",
       "      <td>2023-11-12 09:53:23</td>\n",
       "      <td>75.1</td>\n",
       "      <td>80.400002</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>09:53:23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482695</th>\n",
       "      <td>482696</td>\n",
       "      <td>2023-11-12 09:53:24</td>\n",
       "      <td>75.5</td>\n",
       "      <td>80.400002</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>09:53:24</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482696</th>\n",
       "      <td>482697</td>\n",
       "      <td>2023-11-12 09:53:25</td>\n",
       "      <td>75.3</td>\n",
       "      <td>80.400002</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>09:53:25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482697</th>\n",
       "      <td>482698</td>\n",
       "      <td>2023-11-12 09:53:26</td>\n",
       "      <td>74.9</td>\n",
       "      <td>80.400002</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>09:53:26</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482698</th>\n",
       "      <td>482699</td>\n",
       "      <td>2023-11-12 09:53:27</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.400002</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>09:53:27</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482699 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Series                start  Altitude   Humidity  Temperature  \\\n",
       "0            1  2023-10-23 17:12:39      79.0  82.500000    29.299999   \n",
       "1            2  2023-10-23 17:12:40      78.7  82.500000    29.299999   \n",
       "2            3  2023-10-23 17:12:41      78.4  82.500000    29.299999   \n",
       "3            4  2023-10-23 17:12:42      78.0  82.500000    29.299999   \n",
       "4            5  2023-10-23 17:12:43      77.7  82.500000    29.299999   \n",
       "...        ...                  ...       ...        ...          ...   \n",
       "482694  482695  2023-11-12 09:53:23      75.1  80.400002    30.799999   \n",
       "482695  482696  2023-11-12 09:53:24      75.5  80.400002    30.799999   \n",
       "482696  482697  2023-11-12 09:53:25      75.3  80.400002    30.799999   \n",
       "482697  482698  2023-11-12 09:53:26      74.9  80.400002    30.799999   \n",
       "482698  482699  2023-11-12 09:53:27      75.0  80.400002    30.799999   \n",
       "\n",
       "            Time   Day  Hour_of_Day  IsEJeep1  IsEJeep2  ...  \\\n",
       "0       17:12:39  23.0         17.0         1         0  ...   \n",
       "1       17:12:40  23.0         17.0         1         0  ...   \n",
       "2       17:12:41  23.0         17.0         1         0  ...   \n",
       "3       17:12:42  23.0         17.0         1         0  ...   \n",
       "4       17:12:43  23.0         17.0         1         0  ...   \n",
       "...          ...   ...          ...       ...       ...  ...   \n",
       "482694  09:53:23  12.0          9.0         0         1  ...   \n",
       "482695  09:53:24  12.0          9.0         0         1  ...   \n",
       "482696  09:53:25  12.0          9.0         0         1  ...   \n",
       "482697  09:53:26  12.0          9.0         0         1  ...   \n",
       "482698  09:53:27  12.0          9.0         0         1  ...   \n",
       "\n",
       "        Next Time to Xavier Hall  Next Time to Fine Arts Annex  \\\n",
       "0                       06:12:33                      06:41:23   \n",
       "1                       06:12:33                      06:41:23   \n",
       "2                       06:12:33                      06:41:23   \n",
       "3                       06:12:33                      06:41:23   \n",
       "4                       06:12:33                      06:41:23   \n",
       "...                          ...                           ...   \n",
       "482694                       NaN                           NaN   \n",
       "482695                       NaN                           NaN   \n",
       "482696                       NaN                           NaN   \n",
       "482697                       NaN                           NaN   \n",
       "482698                       NaN                           NaN   \n",
       "\n",
       "        Next Time to Loyola House of Studies  Next Time to Grade School  \\\n",
       "0                                   17:24:22                   17:30:29   \n",
       "1                                   17:24:22                   17:30:29   \n",
       "2                                   17:24:22                   17:30:29   \n",
       "3                                   17:24:22                   17:30:29   \n",
       "4                                   17:24:22                   17:30:29   \n",
       "...                                      ...                        ...   \n",
       "482694                                   NaN                        NaN   \n",
       "482695                                   NaN                        NaN   \n",
       "482696                                   NaN                        NaN   \n",
       "482697                                   NaN                        NaN   \n",
       "482698                                   NaN                        NaN   \n",
       "\n",
       "        Next Time to Gate 2.5  Next Time to Leong Hall  Encoded Day  \\\n",
       "0                    17:16:30                 17:21:38            1   \n",
       "1                    17:34:36                 17:21:38            1   \n",
       "2                    17:34:36                 17:21:38            1   \n",
       "3                    17:34:36                 17:21:38            1   \n",
       "4                    17:34:36                 17:21:38            1   \n",
       "...                       ...                      ...          ...   \n",
       "482694                    NaN                      NaN            7   \n",
       "482695                    NaN                      NaN            7   \n",
       "482696                    NaN                      NaN            7   \n",
       "482697                    NaN                      NaN            7   \n",
       "482698                    NaN                      NaN            7   \n",
       "\n",
       "        Encoded Station  Encoded Prev Station  Encoded Next Station  \n",
       "0                     8                     8                     1  \n",
       "1                     0                     8                     1  \n",
       "2                     0                     8                     1  \n",
       "3                     0                     8                     1  \n",
       "4                     0                     8                     1  \n",
       "...                 ...                   ...                   ...  \n",
       "482694                5                     4                     5  \n",
       "482695                5                     4                     5  \n",
       "482696                5                     4                     5  \n",
       "482697                5                     4                     5  \n",
       "482698                5                     4                     5  \n",
       "\n",
       "[482699 rows x 43 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data Preprocessing/Out.csv')\n",
    "df.tail(10)\n",
    "df.columns = ['Series', 'start', 'Altitude', 'Humidity', 'Temperature', 'Time',\n",
    "       'Day', 'Hour_of_Day', 'IsEJeep1', 'IsEJeep2', 'IsEJeep3', 'Latitude',\n",
    "       'Longitude', 'Lat Diff', 'Long Diff', 'Distance', 'IsStation',\n",
    "       'IsCharging', 'Cum Distance', 'Next Station Lat', 'Next Station Long',\n",
    "       'Abs Distance', 'Percent Distance', 'Prev Station Lat',\n",
    "       'Prev Station Long', 'Prev Abs Distance', 'Prev Cum Distance',\n",
    "       'Previous Time to Xavier Hall', 'Previous Time to Fine Arts Annex',\n",
    "       'Previous Time to Loyola House of Studies',\n",
    "       'Previous Time to Grade School', 'Previous Time to Gate 2.5',\n",
    "       'Previous Time to Leong Hall', 'Next Time to Xavier Hall',\n",
    "       'Next Time to Fine Arts Annex', 'Next Time to Loyola House of Studies',\n",
    "       'Next Time to Grade School', 'Next Time to Gate 2.5',\n",
    "       'Next Time to Leong Hall', 'Encoded Day', 'Encoded Station',\n",
    "       'Encoded Prev Station', 'Encoded Next Station']\n",
    "# df.drop(columns=['Datetime'], inplace=True)\n",
    "\n",
    "df['Series'] = df['Series'] + 1\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make target column\n",
    "df['target'] = df.apply(lambda x: [x['Next Time to Xavier Hall'], x['Next Time to Fine Arts Annex'], x['Next Time to Loyola House of Studies'], x['Next Time to Grade School'], x['Next Time to Gate 2.5'], x['Next Time to Leong Hall']], axis=1)\n",
    "df.drop(columns=['Next Time to Xavier Hall', 'Next Time to Fine Arts Annex', 'Next Time to Loyola House of Studies', 'Next Time to Grade School', 'Next Time to Gate 2.5', 'Next Time to Leong Hall'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312017, 38), (170682, 38), (396188, 38))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train-test set\n",
    "train = df[df['Day'] < 16]\n",
    "test = df[df['Day'] >= 16]\n",
    "validation = df[df['Day'] < 17]\n",
    "\n",
    "# reset index\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "validation.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# check shape\n",
    "train.shape, test.shape, validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Series', 'start', 'Altitude', 'Humidity', 'Temperature', 'Time', 'Day', 'Hour_of_Day', 'IsEJeep1', 'IsEJeep2', 'IsEJeep3', 'Latitude', 'Longitude', 'Lat Diff', 'Long Diff', 'Distance', 'IsStation', 'IsCharging', 'Cum Distance', 'Next Station Lat', 'Next Station Long', 'Abs Distance', 'Percent Distance', 'Prev Station Lat', 'Prev Station Long', 'Prev Abs Distance', 'Prev Cum Distance', 'Previous Time to Xavier Hall', 'Previous Time to Fine Arts Annex', 'Previous Time to Loyola House of Studies', 'Previous Time to Grade School', 'Previous Time to Gate 2.5', 'Previous Time to Leong Hall', 'Encoded Day', 'Encoded Station', 'Encoded Prev Station', 'Encoded Next Station', 'target'],\n",
       "        num_rows: 312017\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Series', 'start', 'Altitude', 'Humidity', 'Temperature', 'Time', 'Day', 'Hour_of_Day', 'IsEJeep1', 'IsEJeep2', 'IsEJeep3', 'Latitude', 'Longitude', 'Lat Diff', 'Long Diff', 'Distance', 'IsStation', 'IsCharging', 'Cum Distance', 'Next Station Lat', 'Next Station Long', 'Abs Distance', 'Percent Distance', 'Prev Station Lat', 'Prev Station Long', 'Prev Abs Distance', 'Prev Cum Distance', 'Previous Time to Xavier Hall', 'Previous Time to Fine Arts Annex', 'Previous Time to Loyola House of Studies', 'Previous Time to Grade School', 'Previous Time to Gate 2.5', 'Previous Time to Leong Hall', 'Encoded Day', 'Encoded Station', 'Encoded Prev Station', 'Encoded Next Station', 'target'],\n",
       "        num_rows: 170682\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Series', 'start', 'Altitude', 'Humidity', 'Temperature', 'Time', 'Day', 'Hour_of_Day', 'IsEJeep1', 'IsEJeep2', 'IsEJeep3', 'Latitude', 'Longitude', 'Lat Diff', 'Long Diff', 'Distance', 'IsStation', 'IsCharging', 'Cum Distance', 'Next Station Lat', 'Next Station Long', 'Abs Distance', 'Percent Distance', 'Prev Station Lat', 'Prev Station Long', 'Prev Abs Distance', 'Prev Cum Distance', 'Previous Time to Xavier Hall', 'Previous Time to Fine Arts Annex', 'Previous Time to Loyola House of Studies', 'Previous Time to Grade School', 'Previous Time to Gate 2.5', 'Previous Time to Leong Hall', 'Encoded Day', 'Encoded Station', 'Encoded Prev Station', 'Encoded Next Station', 'target'],\n",
       "        num_rows: 396188\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = Dataset.from_pandas(train)\n",
    "test_set = Dataset.from_pandas(test)\n",
    "validation_set = Dataset.from_pandas(validation)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "\n",
    "dataset['train'] = train_set\n",
    "dataset['test'] = test_set\n",
    "dataset['validation'] = validation_set\n",
    "\n",
    "\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Probabilistic Time Series Forecasting with Informer\n",
    "https://huggingface.co/blog/informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probsparse_attention(query_states, key_states, value_states, sampling_factor=5):\n",
    "    \"\"\"\n",
    "    Compute the probsparse self-attention.\n",
    "    Input shape: Batch x Time x Channel\n",
    "\n",
    "    Note the additional `sampling_factor` input.\n",
    "    \"\"\"\n",
    "    # get input sizes with logs\n",
    "    L_K = key_states.size(1)\n",
    "    L_Q = query_states.size(1)\n",
    "    log_L_K = np.ceil(np.log1p(L_K)).astype(\"int\").item()\n",
    "    log_L_Q = np.ceil(np.log1p(L_Q)).astype(\"int\").item()\n",
    "\n",
    "    # calculate a subset of samples to slice from K and create Q_K_sample\n",
    "    U_part = min(sampling_factor * L_Q * log_L_K, L_K)\n",
    "\n",
    "    # create Q_K_sample (the q_i * k_j^T term in the sparsity measurement)\n",
    "    index_sample = torch.randint(0, L_K, (U_part,))\n",
    "    K_sample = key_states[:, index_sample, :]\n",
    "    Q_K_sample = torch.bmm(query_states, K_sample.transpose(1, 2))\n",
    "\n",
    "    # calculate the query sparsity measurement with Q_K_sample\n",
    "    M = Q_K_sample.max(dim=-1)[0] - torch.div(Q_K_sample.sum(dim=-1), L_K)\n",
    "\n",
    "    # calculate u to find the Top-u queries under the sparsity measurement\n",
    "    u = min(sampling_factor * log_L_Q, L_Q)\n",
    "    M_top = M.topk(u, sorted=False)[1]\n",
    "\n",
    "    # calculate Q_reduce as query_states[:, M_top]\n",
    "    dim_for_slice = torch.arange(query_states.size(0)).unsqueeze(-1)\n",
    "    Q_reduce = query_states[dim_for_slice, M_top]  # size: c*log_L_Q x channel\n",
    "\n",
    "    # and now, same as the canonical\n",
    "    d_k = query_states.size(-1)\n",
    "    attn_scores = torch.bmm(Q_reduce, key_states.transpose(-2, -1))  # Q_reduce x K^T\n",
    "    attn_scores = attn_scores / math.sqrt(d_k)\n",
    "    attn_probs = nn.functional.softmax(attn_scores, dim=-1)\n",
    "    attn_output = torch.bmm(attn_probs, value_states)\n",
    "\n",
    "    return attn_output, attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvLayer is a class with forward pass applying ELU and MaxPool1d\n",
    "def informer_encoder_forward(x_input, num_encoder_layers=3, distil=True):\n",
    "    # Initialize the convolution layers\n",
    "    if distil:\n",
    "        conv_layers = nn.ModuleList([ConvLayer() for _ in range(num_encoder_layers - 1)])\n",
    "        conv_layers.append(None)\n",
    "    else:\n",
    "        conv_layers = [None] * num_encoder_layers\n",
    "    \n",
    "    # Apply conv_layer between each encoder_layer\n",
    "    for encoder_layer, conv_layer in zip(encoder_layers, conv_layers):\n",
    "        output = encoder_layer(x_input)\n",
    "        if conv_layer is not None:\n",
    "            output = conv_layer(loutput)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84171"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example = dataset[\"train\"][0]\n",
    "validation_example = dataset[\"validation\"][0]\n",
    "\n",
    "freq = \"1S\"\n",
    "prediction_length = len(validation) - len(train)\n",
    "\n",
    "prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_of_samples = 200000\n",
    "\n",
    "figure, axes = plt.subplots()\n",
    "axes.plot(train_example[\"target\"][-num_of_samples:], color=\"blue\")\n",
    "axes.plot(\n",
    "    validation_example[\"target\"][-num_of_samples - prediction_length :],\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(10_000)\n",
    "def convert_to_pandas_period(date, freq):\n",
    "    return pd.Period(date, freq)\n",
    "\n",
    "\n",
    "def transform_start_field(batch, freq):\n",
    "    batch[\"start\"] = [convert_to_pandas_period(date, freq) for date in batch[\"start\"]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "train_dataset.set_transform(partial(transform_start_field, freq=freq))\n",
    "test_dataset.set_transform(partial(transform_start_field, freq=freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert 06:40:0306:19:1606:23:4106:24:3806:57:3606:31:31 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1692\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(x)\n\u001b[1;32m   1693\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1694\u001b[0m     \u001b[39m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '06:40:0306:19:1606:23:4106:24:3806:57:3606:31:31'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1696\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39;49m(x)\n\u001b[1;32m   1697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1698\u001b[0m     \u001b[39m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/anyahabana/Tools/VisualStudioCodeProjects/VHS THESIS/VHS-Thesis/Baseline Models v4/Transformers v4.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anyahabana/Tools/VisualStudioCodeProjects/VHS%20THESIS/VHS-Thesis/Baseline%20Models%20v4/Transformers%20v4.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_grouper \u001b[39m=\u001b[39m MultivariateGrouper(max_target_dim\u001b[39m=\u001b[39mnum_of_variates)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anyahabana/Tools/VisualStudioCodeProjects/VHS%20THESIS/VHS-Thesis/Baseline%20Models%20v4/Transformers%20v4.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m test_grouper \u001b[39m=\u001b[39m MultivariateGrouper(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anyahabana/Tools/VisualStudioCodeProjects/VHS%20THESIS/VHS-Thesis/Baseline%20Models%20v4/Transformers%20v4.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     max_target_dim\u001b[39m=\u001b[39mnum_of_variates,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anyahabana/Tools/VisualStudioCodeProjects/VHS%20THESIS/VHS-Thesis/Baseline%20Models%20v4/Transformers%20v4.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     num_test_dates\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(test_dataset) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_of_variates, \u001b[39m# number of rolling test windows\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anyahabana/Tools/VisualStudioCodeProjects/VHS%20THESIS/VHS-Thesis/Baseline%20Models%20v4/Transformers%20v4.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anyahabana/Tools/VisualStudioCodeProjects/VHS%20THESIS/VHS-Thesis/Baseline%20Models%20v4/Transformers%20v4.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m multi_variate_train_dataset \u001b[39m=\u001b[39m train_grouper(train_dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anyahabana/Tools/VisualStudioCodeProjects/VHS%20THESIS/VHS-Thesis/Baseline%20Models%20v4/Transformers%20v4.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m multi_variate_test_dataset \u001b[39m=\u001b[39m test_grouper(test_dataset)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gluonts/dataset/multivariate_grouper.py:88\u001b[0m, in \u001b[0;36mMultivariateGrouper.__call__\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, dataset: Dataset) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset:\n\u001b[1;32m     87\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess(dataset)\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_group_all(dataset)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gluonts/dataset/multivariate_grouper.py:124\u001b[0m, in \u001b[0;36mMultivariateGrouper._group_all\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_group_all\u001b[39m(\u001b[39mself\u001b[39m, dataset: Dataset) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset:\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_test_dates \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m         grouped_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_train_data(dataset)\n\u001b[1;32m    125\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m         grouped_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_test_data(dataset)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gluonts/dataset/multivariate_grouper.py:134\u001b[0m, in \u001b[0;36mMultivariateGrouper._prepare_train_data\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    130\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mgroup training time series to datasets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[39m# Creates a single multivariate time series from the\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m# univariate series in the dataset\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m grouped_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform_target(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_align_data_entry, dataset)\n\u001b[1;32m    135\u001b[0m grouped_data[FieldName\u001b[39m.\u001b[39mTARGET] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(\n\u001b[1;32m    136\u001b[0m     grouped_data[FieldName\u001b[39m.\u001b[39mTARGET]\n\u001b[1;32m    137\u001b[0m )\n\u001b[1;32m    139\u001b[0m fields \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataset), {})\u001b[39m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gluonts/dataset/multivariate_grouper.py:208\u001b[0m, in \u001b[0;36mMultivariateGrouper._transform_target\u001b[0;34m(funcs, dataset)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_target\u001b[39m(funcs, dataset: Dataset) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataEntry:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mreturn\u001b[39;00m {FieldName\u001b[39m.\u001b[39mTARGET: [funcs(data) \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dataset]}\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gluonts/dataset/multivariate_grouper.py:208\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_target\u001b[39m(funcs, dataset: Dataset) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataEntry:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mreturn\u001b[39;00m {FieldName\u001b[39m.\u001b[39mTARGET: [funcs(data) \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dataset]}\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/gluonts/dataset/multivariate_grouper.py:192\u001b[0m, in \u001b[0;36mMultivariateGrouper._align_data_entry\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_align_data_entry\u001b[39m(\u001b[39mself\u001b[39m, data: DataEntry) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    185\u001b[0m     ts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_ts(data)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m ts\u001b[39m.\u001b[39mreindex(\n\u001b[1;32m    187\u001b[0m         pd\u001b[39m.\u001b[39mperiod_range(\n\u001b[1;32m    188\u001b[0m             start\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_timestamp,\n\u001b[1;32m    189\u001b[0m             end\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_timestamp,\n\u001b[1;32m    190\u001b[0m             freq\u001b[39m=\u001b[39mdata[FieldName\u001b[39m.\u001b[39mSTART]\u001b[39m.\u001b[39mfreq,\n\u001b[1;32m    191\u001b[0m         ),\n\u001b[0;32m--> 192\u001b[0m         fill_value\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_fill_function(ts),\n\u001b[1;32m    193\u001b[0m     )\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/numpy/core/fromnumeric.py:3462\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3460\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   3461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3462\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3464\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   3465\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11539\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11540\u001b[0m     _num_doc,\n\u001b[1;32m  11541\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11554\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11555\u001b[0m ):\n\u001b[0;32m> 11556\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmean(\u001b[39mself\u001b[39;49m, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  11195\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11196\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11199\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11200\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[1;32m  11202\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11203\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11154\u001b[0m     nv\u001b[39m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[39m=\u001b[39mname)\n\u001b[1;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m> 11158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11159\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[1;32m  11160\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4665\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   4666\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not allow \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mnumeric_only\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4667\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith non-numeric dtypes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4668\u001b[0m     )\n\u001b[1;32m   4669\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 4670\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    156\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[0;32m--> 421\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[1;32m    424\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    724\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[1;32m    726\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[0;32m--> 727\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[1;32m    729\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    730\u001b[0m     count \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1696\u001b[0m             x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39m(x)\n\u001b[1;32m   1697\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1698\u001b[0m             \u001b[39m# e.g. \"foo\"\u001b[39;00m\n\u001b[0;32m-> 1699\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert 06:40:0306:19:1606:23:4106:24:3806:57:3606:31:31 to numeric"
     ]
    }
   ],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "\n",
    "num_of_variates = len(train_dataset)\n",
    "\n",
    "train_grouper = MultivariateGrouper(max_target_dim=num_of_variates)\n",
    "test_grouper = MultivariateGrouper(\n",
    "    max_target_dim=num_of_variates,\n",
    "    num_test_dates=len(test_dataset) // num_of_variates, # number of rolling test windows\n",
    ")\n",
    "\n",
    "multi_variate_train_dataset = train_grouper(train_dataset)\n",
    "multi_variate_test_dataset = test_grouper(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_variate_train_example = multi_variate_train_dataset[0]\n",
    "multi_variate_train_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.time_feature import get_lags_for_frequency\n",
    "\n",
    "lags_sequence = get_lags_for_frequency(freq)\n",
    "lags_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.time_feature import time_features_from_frequency_str\n",
    "\n",
    "time_features = time_features_from_frequency_str(freq)\n",
    "time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix since data set already has this\n",
    "\n",
    "from pandas.core.arrays.period import period_array\n",
    "\n",
    "timestamp = pd.Period(\"2015-01-01 01:00:01\", freq=freq)\n",
    "timestamp_as_index = pd.PeriodIndex(data=period_array([timestamp]))\n",
    "additional_features = [\n",
    "    (time_feature.__name__, time_feature(timestamp_as_index))\n",
    "    for time_feature in time_features\n",
    "]\n",
    "dict(additional_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import InformerConfig, InformerForPrediction\n",
    "\n",
    "config = InformerConfig(\n",
    "    # in the multivariate setting, input_size is the number of variates in the time series per time step\n",
    "    input_size=num_of_variates,\n",
    "    # prediction length:\n",
    "    prediction_length=prediction_length,\n",
    "    # context length:\n",
    "    context_length=prediction_length * 2,\n",
    "    # lags value copied from 1 week before:\n",
    "    lags_sequence=[1, 24 * 7],\n",
    "    # we'll add 5 time features (\"hour_of_day\", ..., and \"age\"):\n",
    "    num_time_features=len(time_features) + 1,\n",
    "    \n",
    "    # informer params:\n",
    "    dropout=0.1,\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=4,\n",
    "    # project input from num_of_variates*len(lags_sequence)+num_time_features to:\n",
    "    d_model=64,\n",
    ")\n",
    "\n",
    "model = InformerForPrediction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.distribution_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transformations\n",
    "\n",
    "from gluonts.time_feature import TimeFeature\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.transform import (\n",
    "    AddAgeFeature,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    AsNumpyArray,\n",
    "    Chain,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    InstanceSplitter,\n",
    "    RemoveFields,\n",
    "    SelectFields,\n",
    "    SetField,\n",
    "    TestSplitSampler,\n",
    "    Transformation,\n",
    "    ValidationSplitSampler,\n",
    "    VstackFeatures,\n",
    "    RenameFields,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "\n",
    "\n",
    "def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n",
    "    # create list of fields to remove later\n",
    "    remove_field_names = []\n",
    "    if config.num_static_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
    "    if config.num_dynamic_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
    "    if config.num_static_categorical_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_CAT)\n",
    "\n",
    "    return Chain(\n",
    "        # step 1: remove static/dynamic fields if not specified\n",
    "        [RemoveFields(field_names=remove_field_names)]\n",
    "        # step 2: convert the data to NumPy (potentially not needed)\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_CAT,\n",
    "                    expected_ndim=1,\n",
    "                    dtype=int,\n",
    "                )\n",
    "            ]\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else []\n",
    "        )\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_REAL,\n",
    "                    expected_ndim=1,\n",
    "                )\n",
    "            ]\n",
    "            if config.num_static_real_features > 0\n",
    "            else []\n",
    "        )\n",
    "        + [\n",
    "            AsNumpyArray(\n",
    "                field=FieldName.TARGET,\n",
    "                # we expect an extra dim for the multivariate case:\n",
    "                expected_ndim=1 if config.input_size == 1 else 2,\n",
    "            ),\n",
    "            # step 3: handle the NaN's by filling in the target with zero\n",
    "            # and return the mask (which is in the observed values)\n",
    "            # true for observed values, false for nan's\n",
    "            # the decoder uses this mask (no loss is incurred for unobserved values)\n",
    "            # see loss_weights inside the xxxForPrediction model\n",
    "            AddObservedValuesIndicator(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.OBSERVED_VALUES,\n",
    "            ),\n",
    "            # step 4: add temporal features based on freq of the dataset\n",
    "            # these serve as positional encodings\n",
    "            AddTimeFeatures(\n",
    "                start_field=FieldName.START,\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                time_features=time_features_from_frequency_str(freq),\n",
    "                pred_length=config.prediction_length,\n",
    "            ),\n",
    "            # step 5: add another temporal feature (just a single number)\n",
    "            # tells the model where in the life the value of the time series is\n",
    "            # sort of running counter\n",
    "            AddAgeFeature(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_AGE,\n",
    "                pred_length=config.prediction_length,\n",
    "                log_scale=True,\n",
    "            ),\n",
    "            # step 6: vertically stack all the temporal features into the key FEAT_TIME\n",
    "            VstackFeatures(\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
    "                + (\n",
    "                    [FieldName.FEAT_DYNAMIC_REAL]\n",
    "                    if config.num_dynamic_real_features > 0\n",
    "                    else []\n",
    "                ),\n",
    "            ),\n",
    "            # step 7: rename to match HuggingFace names\n",
    "            RenameFields(\n",
    "                mapping={\n",
    "                    FieldName.FEAT_STATIC_CAT: \"static_categorical_features\",\n",
    "                    FieldName.FEAT_STATIC_REAL: \"static_real_features\",\n",
    "                    FieldName.FEAT_TIME: \"time_features\",\n",
    "                    FieldName.TARGET: \"values\",\n",
    "                    FieldName.OBSERVED_VALUES: \"observed_mask\",\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define InstanceSplitter\n",
    "\n",
    "from gluonts.transform.sampler import InstanceSampler\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def create_instance_splitter(\n",
    "    config: PretrainedConfig,\n",
    "    mode: str,\n",
    "    train_sampler: Optional[InstanceSampler] = None,\n",
    "    validation_sampler: Optional[InstanceSampler] = None,\n",
    ") -> Transformation:\n",
    "    assert mode in [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "    instance_sampler = {\n",
    "        \"train\": train_sampler\n",
    "        or ExpectedNumInstanceSampler(\n",
    "            num_instances=1.0, min_future=config.prediction_length\n",
    "        ),\n",
    "        \"validation\": validation_sampler\n",
    "        or ValidationSplitSampler(min_future=config.prediction_length),\n",
    "        \"test\": TestSplitSampler(),\n",
    "    }[mode]\n",
    "\n",
    "    return InstanceSplitter(\n",
    "        target_field=\"values\",\n",
    "        is_pad_field=FieldName.IS_PAD,\n",
    "        start_field=FieldName.START,\n",
    "        forecast_start_field=FieldName.FORECAST_START,\n",
    "        instance_sampler=instance_sampler,\n",
    "        past_length=config.context_length + max(config.lags_sequence),\n",
    "        future_length=config.prediction_length,\n",
    "        time_series_fields=[\"time_features\", \"observed_mask\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "\n",
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from gluonts.itertools import Cached, Cyclic\n",
    "from gluonts.dataset.loader import as_stacked_batches\n",
    "\n",
    "\n",
    "def create_train_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    num_batches_per_epoch: int,\n",
    "    shuffle_buffer_length: Optional[int] = None,\n",
    "    cache_data: bool = True,\n",
    "    **kwargs,\n",
    ") -> Iterable:\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
    "        \"future_values\",\n",
    "        \"future_observed_mask\",\n",
    "    ]\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=True)\n",
    "    if cache_data:\n",
    "        transformed_data = Cached(transformed_data)\n",
    "\n",
    "    # we initialize a Training instance\n",
    "    instance_splitter = create_instance_splitter(config, \"train\")\n",
    "\n",
    "    # the instance splitter will sample a window of\n",
    "    # context length + lags + prediction length (from all the possible transformed time series, 1 in our case)\n",
    "    # randomly from within the target time series and return an iterator.\n",
    "    stream = Cyclic(transformed_data).stream()\n",
    "    training_instances = instance_splitter.apply(\n",
    "        stream, is_train=True\n",
    "    )\n",
    "    \n",
    "    return as_stacked_batches(\n",
    "        training_instances,\n",
    "        batch_size=batch_size,\n",
    "        shuffle_buffer_length=shuffle_buffer_length,\n",
    "        field_names=TRAINING_INPUT_NAMES,\n",
    "        output_type=torch.tensor,\n",
    "        num_batches_per_epoch=num_batches_per_epoch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=False)\n",
    "\n",
    "    # we create a Test Instance splitter which will sample the very last\n",
    "    # context window seen during training only for the encoder.\n",
    "    instance_sampler = create_instance_splitter(config, \"test\")\n",
    "\n",
    "    # we apply the transformations in test mode\n",
    "    testing_instances = instance_sampler.apply(transformed_data, is_train=False)\n",
    "    \n",
    "    return as_stacked_batches(\n",
    "        testing_instances,\n",
    "        batch_size=batch_size,\n",
    "        output_type=torch.tensor,\n",
    "        field_names=PREDICTION_INPUT_NAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_train_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=multi_variate_train_dataset,\n",
    "    batch_size=256,\n",
    "    num_batches_per_epoch=100,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_dataloader = create_test_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=multi_variate_test_dataset,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for k, v in batch.items():\n",
    "    k, v.shape, v.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Pass\n",
    "\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"]\n",
    "    if config.num_static_categorical_features > 0\n",
    "    else None,\n",
    "    static_real_features=batch[\"static_real_features\"]\n",
    "    if config.num_static_real_features > 0\n",
    "    else None,\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    "    future_observed_mask=batch[\"future_observed_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss:\", outputs.loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from torch.optim import AdamW\n",
    "\n",
    "epochs = 25\n",
    "loss_history = []\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)\n",
    "\n",
    "model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else None,\n",
    "            static_real_features=batch[\"static_real_features\"].to(device)\n",
    "            if config.num_static_real_features > 0\n",
    "            else None,\n",
    "            past_time_features=batch[\"past_time_features\"].to(device),\n",
    "            past_values=batch[\"past_values\"].to(device),\n",
    "            future_time_features=batch[\"future_time_features\"].to(device),\n",
    "            future_values=batch[\"future_values\"].to(device),\n",
    "            past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "            future_observed_mask=batch[\"future_observed_mask\"].to(device),\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backpropagation\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "        if idx % 100 == 0:\n",
    "            print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view training\n",
    "loss_history = np.array(loss_history).reshape(-1)\n",
    "x = range(loss_history.shape[0])\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, loss_history, label=\"train\")\n",
    "plt.title(\"Loss\", fontsize=15)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"nll\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "forecasts_ = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    outputs = model.generate(\n",
    "        static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "        if config.num_static_categorical_features > 0\n",
    "        else None,\n",
    "        static_real_features=batch[\"static_real_features\"].to(device)\n",
    "        if config.num_static_real_features > 0\n",
    "        else None,\n",
    "        past_time_features=batch[\"past_time_features\"].to(device),\n",
    "        past_values=batch[\"past_values\"].to(device),\n",
    "        future_time_features=batch[\"future_time_features\"].to(device),\n",
    "        past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "    )\n",
    "    forecasts_.append(outputs.sequences.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = np.vstack(forecasts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to RMSE & Adjusted R^2\n",
    "\n",
    "from evaluate import load\n",
    "from gluonts.time_feature import get_seasonality\n",
    "\n",
    "mase_metric = load(\"evaluate-metric/mase\")\n",
    "smape_metric = load(\"evaluate-metric/smape\")\n",
    "\n",
    "forecast_median = np.median(forecasts, 1).squeeze(0).T\n",
    "\n",
    "mase_metrics = []\n",
    "smape_metrics = []\n",
    "\n",
    "for item_id, ts in enumerate(test_dataset):\n",
    "    training_data = ts[\"target\"][:-prediction_length]\n",
    "    ground_truth = ts[\"target\"][-prediction_length:]\n",
    "    mase = mase_metric.compute(\n",
    "        predictions=forecast_median[item_id],\n",
    "        references=np.array(ground_truth),\n",
    "        training=np.array(training_data),\n",
    "        periodicity=get_seasonality(freq),\n",
    "    )\n",
    "    mase_metrics.append(mase[\"mase\"])\n",
    "\n",
    "    smape = smape_metric.compute(\n",
    "        predictions=forecast_median[item_id],\n",
    "        references=np.array(ground_truth),\n",
    "    )\n",
    "    smape_metrics.append(smape[\"smape\"])\n",
    "    \n",
    "np.mean(mase_metrics)\n",
    "np.mean(smape_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mase_metrics, smape_metrics, alpha=0.2)\n",
    "plt.xlabel(\"MASE\")\n",
    "plt.ylabel(\"sMAPE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "def plot(ts_index, mv_index):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    index = pd.period_range(\n",
    "        start=multi_variate_test_dataset[ts_index][FieldName.START],\n",
    "        periods=len(multi_variate_test_dataset[ts_index][FieldName.TARGET]),\n",
    "        freq=multi_variate_test_dataset[ts_index][FieldName.START].freq,\n",
    "    ).to_timestamp()\n",
    "\n",
    "    ax.xaxis.set_minor_locator(mdates.HourLocator())\n",
    "\n",
    "    ax.plot(\n",
    "        index[-2 * prediction_length :],\n",
    "        multi_variate_test_dataset[ts_index][\"target\"][mv_index, -2 * prediction_length :],\n",
    "        label=\"actual\",\n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        index[-prediction_length:],\n",
    "        forecasts[ts_index, ..., mv_index].mean(axis=0),\n",
    "        label=\"mean\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        index[-prediction_length:],\n",
    "        forecasts[ts_index, ..., mv_index].mean(0)\n",
    "        - forecasts[ts_index, ..., mv_index].std(axis=0),\n",
    "        forecasts[ts_index, ..., mv_index].mean(0)\n",
    "        + forecasts[ts_index, ..., mv_index].std(axis=0),\n",
    "        alpha=0.2,\n",
    "        interpolate=True,\n",
    "        label=\"+/- 1-std\",\n",
    "    )\n",
    "    ax.legend()\n",
    "    fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(0, 344)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
